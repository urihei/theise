\subsection{Approximate inference}
\label{sec:approx}
Graphical models is a power full tool.
In order it to be of use, an algorithm should be found that could answer queries based on the model, in other words preform inference.
As written above, exact inference in the general is NP-complete.
Hence the importance of finding an approximate inference.
I will focus in this introduction only on the problem of finding the marginals (not the MAP problem) since in learning it is of more use as I will show later.

The approximate inference algorithm can be divided in to two main categories: variational inference, and sampling.
I will now try to go over the main principles of the two categories.
\subsection{Variational Methods}
\label{sec:variational_methods}
I will follow in this section the excellent work by \cite{wainwright2008graphical}.
We are interested in finding $\muv$ the marginals.
First we need to define our search space - the marginal-ploytope $\margpoly^G$.
\be
\margpoly^G = \left\{ \muv \in [0,1]^d\ \left| 
\begin{array}{lr}
  \exists \thetav \in \Omega^G\ s.t. \\
  \forall i \in V \land \forall x_i \in \cX &   P(x_i;\thetav) = \mu_i(x_i)\\
  \forall ij \in E \land \forall x_i, x_j \in \cX &P(x_i,x_j;\thetav) = \mu_{ij}(x_i,x_j)
\end{array} \right. \right\}
\ee
Now we can define the conjugate dual 
\be
A^*(\muv) = \sup_{\thetav \in \Omega^G} \left\{\muv \cdot \thetav - A(\thetav)\right\}
\ee
Two things should be noted. The first is that if $\muv \in \margpoly^G$\footnote{This imply only for marginals in the inner part of the marginal polytope. For marginals on the boundaries more delicate treatment should be given} than $A^*(\muv) = -H(P(\xx;\thetav(\muv)))$ the conjugate of the log partition function is equals to the entropy of the probability that its marginals are $\muv$.
Second that this is similar to the maximum likelihood objective (see \secref{sec:max_likelihood}).
It can be shown that $A(\thetav)$ is a convex function of $\thetav$ hence ${A^{*}}^* = A$, now the variational expression of $A(\thetav)$ can be written as, 
\bean
A(\thetav) &=& \sup_{\muv \in \margpoly^G}\left \{ \muv \cdot \thetav + H(P(\xx;\thetav(\muv))) \right\} \label{eq:variation_A} \\
\muv^{\thetav}&=& \arg \sup_{\muv \in \margpoly^G}\left \{ \muv \cdot \thetav + H(P(\xx;\thetav(\muv))) \right\} \label{eq:arg_variation_A}
\eean
\eqref{eq:arg_variation_A} and \eqref{eq:variation_A} present a new way to infer  the marginals and  calculate the partition function.
Not surprisingly, solving this optimization is hard in itself for two reasons.
The first, the marginal-polytope is a very complex  body - its description is exponential in $d$ the size of $\muv$.
The second, calculating the entropy is a hard problem by itself.
The merit in this representation, is the ability to approximate these two quantities - the entropy and the marginal polytope.

I will present two method of approximation, the first limit both the marginal-polytope and the entropy to a sub-graph of $G$ in a way that both are easy to calculate. 
For example if we select the independent graph it sum down to the mean-field method \cite{peterson1987mean}.
The second method give different approximation to the entropy and marginal polytope.
The local polytope ( defined in \eqref{eq:local_polytope}) is an outer bound and approximation of the marginal-polytope.
While the entropy is approximated by the Bethe-entropy. 
the resulted approximation is the  Bethe approximation which is related to the known algorithm Belief-Propagation\cite{pearl1986fusion, yedidia2000generalized}.
\subsubsection{Mean Field}
Mean field is a technique that approximate a complex model by a simpler one.
%In inference, it approximate the real model marginals by marginals of a simpler model.
More specifically in inference, it replace the marginal polytope (of the true dependencies graph) and the true entropy with marginal polytope of simpler graph and entropy of the model with the simpler dependencies graph.
I will illustrate this technique by choosing the simplest graph - the independent graph denote by $G_I$.
In this case the marginal polytope sum down to,
\be
\margpoly^{G_I} = \left\{\muv \in \Re^{d}\left|
\begin{array}{lr}
\forall i \in V,\ \forall x_i \in \cX & 0\leq \mu_i(x_i)\\
\forall i \in V & \sum_{x \in \cX} \mu_i(x_i) = 1\\
\forall ij \in G,\ x_i,x_j \in \cX & \mu_{ij}(x_i,x_j) = \mu_i(x_i)\mu_j(x_j)
\end{array}
\right.\right\}
\ee
Note that the dimension of the marginals is with respect to the original graph,
moreover, $\margpoly^{G_I} \subseteq \margpoly^{G}$.\\
Now the entropy for this family of models is simply,
\be
H_{G_I}(\muv) = -\sum_{i}\sum_{x_i} \mu_i(x_i)\log\mu_i(x_i)
\ee 
So the partition function can no be written as
\be
A_{G_I}(\thetav) = \sup_{\muv \in \margpoly^{G_I}}\left \{ \muv \cdot \thetav + H_{G_I}(\muv))) \right\} \label{eq:naive_mean_field} \\
\ee
Note that $A(\thetav) \geq A_{G_I}(\thetav)$ since by restricting the marginal polytope the result can only decrease (the entropy is exact on this models family).
Taking the derivative of the right side of \eqref{eq:naive_mean_field} and compare to zero gives
\be
\mu_i(x_i) \propto \exp{\theta_i(x_i) + \sum_{j\in \nei{i}} \sum_{x_j} \theta_{ij}(x_i,x_j)\mu_j(x_j) } \label{eq:naive_iter}
\ee
Iterating through \eqref{eq:naive_iter} will converge since \eqref{eq:naive_mean_field} is a concave function.

The above example demonstrate two important feature of the chosen dependency graph.
First, the entropy should be easy to calculate.
Second, if the resulted equation is convex, the optimization will be easy.
The second feature does not always hold, for example if the dependency graph is a tree. 
The model entropy is the Bethe entropy (see \eqref{eq:bethe_entropy}) which is not a concave function. 
Hence, local maximum could occur and the resulted algorithm may not converge\footnote{ This is not BP, to get BP the optimization should be over the local polytope not the tree polytope}.
\subsubsection{Belief Propagation}
\label{sec:belief}
Belief-Propagation (BP) is a message passing algorithm.
In each cycle\footnote{The order of the messages can effect convergence, hence can be arbitrarily be changed. see for example \cite{elidan2012residual}.} a message is passed from a vertex to all its neighbors.
The message reflect the source vertex belief on the destination vertex probability.
The message is a function of the factor connecting the two vertices and the messages from all neighbors except the destination neighbor.
It continue to cycle until the difference in the messages is very small or after a fix number of cycles.
The messages can be written as, 
\be
\label{eq:belief_propagation}
m_{i \to j}^{t}(x_j) \propto \sum_{x_i \in\cX} \exp{\theta_{i,j}(x_i,x_j)+\theta_{i}(x_i)}\prod_{k \in \nei{i} \setminus j } m_{k \to i}^{t-1} (x_i)
\ee 
Now the resulted pseudo-marginals is calculated by,
\bean
\tau_i(x_i) &\propto& \exp{\theta_i(x_i)} \prod_{k \in \nei{i}} m^T_{k \to i}(x_i) \label{eq:bp_single_marginal}\\
\tau_{ij}(x_i,x_j) &\propto& \exp{\theta_{ij}(x_i,x_j)+\theta_i(x_i)+\theta_j(x_j)} \prod_{k \in \nei{i}\setminus j} m_{k \to i}^{T} (x_i) \prod_{k \in \nei{j}\setminus i}m_{k \to j}^{T} (x_j)\label{eq:bp_pairwise_marginal}
\eean

If the model graph is a tree - BP is exact, the pseudo-marginals are the exact marginals $\tauv^{\thetav} = \muv^{\thetav}$.
There are other models families  where the error of BP marginals can be bound.
Tree-like model is an example of such family\cite{dembo2010ising}, this fact is used in my second paper\cite{heinemann2014inferning}. 
But in the general case the quality of the pseudo-marginals is unknown. 
Moreover, there are cases where BP  does not converge and even when it does the resulted pseudo-marginals may depend on the initial messages $\boldsymbol{m}^0$.
Despite the above BP give good results in practice \cite{willsky2002multiresolution,loeliger2004introduction,kschischang2003codes}.

The first step in understanding BP is to give meaning to the resulted pseudo-marginals.
This was done by \cite{yedidia2000generalized, yedidia2003understanding} they found that the fix point of BP are local minima of the Bethe free energy of the system\footnote{Later \cite{heskes2002stable} refined this result to \textbf{stable} fix point of BP are  local minima of the Bethe approximation}.
Not only that this result gave meaning to BP fix points, it allow theoretical analysis of BP. 
I will now present this result.

As mention earlier, the approximation of \eqref{eq:variation_A} include two parts:
first lets defined the Bethe entropy - an approximation of the true entropy,
\bean
H_B(\tauv) &=& -\sum_{i} (1-d_i)\sum_{x_i}\tau_i(x_i)\log\tau_i(x_i) -\sum_{ij}\sum_{x_i,x_j}\tau_{ij}(x_i,x_j)\log\tau_{ij}(x_i,x_j)\label{eq:bethe_entropy}\\
&=&-\sum_{i}\sum_{x_i}\tau_i(x_i)\log\tau_i(x_i) -\sum_{ij}\sum_{x_i,x_j}\tau_{ij}(x_i,x_j)\log\frac{\tau_{ij}(x_i,x_j)}{\tau_i(x_i)\tau_j(x_j)} \label{eq:bethe_entorpy_information}
\eean
Second  the approximation of the marginal-polytope with the local-polytope.
\be
\label{eq:local_polytope}
\lclmargpoly = \left\{\tauv \in \Re^d\left| 
\begin{array}{lr}
\forall i \in V & \sum_{x_i} \tau_i(x_i) = 1\\
\forall i \in V, \forall x_i \in \cX,\ \forall j \in \nei{j}& \sum_{x_j}\tau_{ij}(x_i,x_j) = \tau_i(x_i)\\
\forall i \in V,\ \forall ij \in E,\ x_i,x_j \in \cX & \tau_i(x_i) \geq 0,\ \tau_{ij}(x_i,x_j) \geq 0
\end{array}\right.\right\}
\ee 
We are now able to write the Bethe approximation to the partition function.
\be
\label{eq:bethe_approximation}
A_B(\thetav) = \sup_{\tauv \in \lclmargpoly} \left\{\thetav \cdot \tauv + H_B(\tauv)\right\}
\ee
And the Bethe energy is $-A_B(\thetav)$.\\
In contrast to the variational free energy, the Bethe free energy is simple to calculate, since the local polytope is describe by a linear number of  constrains and the Bethe entropy calculation is straight forward .
This however come with a price.
First the result must not belong to the marginal-polytope hence not a ``real'' marginal.
Second, the resulted optimization is no longer convex - the Bethe entropy is non-convex function while the true one is convex.
Hence the complexity of optimizing this objective is not clear - I am not aware on any result on the time complexity of Bethe approximation\footnote{In \cite{weller2012bethe} a polynomial algorithm is suggested that approximate the Bethe free energy up to arbitrary precision under some models constrains.}.
%So the importance of \eqref{eq:bethe_approximation} to inference, is its connection to BP.

After defining the Bethe energy , to see the connection to BP we just need to write the Lagrangian of this optimization,
\bea
\mathcal{L}(\thetav,\tauv,\lambdav) &=& -\thetav \cdot \tauv - H_B(\tauv) \\
&+& \sum_i \lambda_i \left(1-\sum_{x_i} \tau_i(x_i)\right) + \sum_{ij}\lambda_{ij}\left(1-\sum_{x_i,x_j}\tau_{ij}(x_i,x_j)\right)\\
&+& \sum_{i} \sum_{j \in \nei{i}}\sum_{x_i}\lambda_{j \to i, x_i}\left(\tau_i(x_i)-\sum_{x_j} \tau_{ij}(x_i,x_j)\right)
\eea
Using \eqref{eq:bethe_entorpy_information} for the Bethe entropy and remembering the derivative of $x\log\frac{x}{a}$ is $\log\frac{x}{a}+1$ the derivatives compare to zero give\footnote{And using the constrain $\sum_{x_i}\tau_{ij}(x_i,x_j) = \tau_j(x_j)$},
\bea
\log{\tau_i(x_i)} &=& \theta_i(x_i)+ \sum_{j \in \nei{i}} \lambda_{j \to i,x_i}-(d_i-1)+\lambda_i\\
\log{\tau_{ij}(x_i,x_j)} &=&  \theta_{ij}(x_i,x_j) - \lambda_{j \to i,x_i} -  \lambda_{i \to j,x_j} +\log \tau_{i}(x_i) +\log \tau_{j}(x_j) -1 +\lambda_{ij}
%\frac{\partial \mathcal{L}(\thetav,\tauv,\lambdav)}{\partial \tau_i(x_i)} &=& \theta_i(x_i) - \log{\tau_i(x_i)}-1 - \sum_{j \in \nei{i}} \lambda_{i \to j,x_i}\\
%\frac{\partial \mathcal{L}(\thetav,\tauv,\lambdav)}{\partial \tau_{ij}(x_i,x_j)} &=& \theta_{ij}(x_i,x_j) + \log{\tau_{ij}(x_i,x_j)} + 1 + \lambda_{i \to j,x_i} + \lambda_{j \to i,x_j}
\eea
taking the exponent and rearranging\footnote{$\lambda_{ij}$,and$\lambda_i$ are part of the normalization a long with the constants.} we have,
\bea
\tau_i(x_i) &\propto& \exp{\theta_i(x_i)}\prod_{j \in \nei{i}} \exp{\lambda_{j \to i,x_i}}\\
\tau_{ij}(x_i,x_j) &\propto&  \exp{\theta_{ij}(x_i,x_j)+\theta_i(x_i)+\theta_j(x_j)} \prod_{k \in \nei{i}\setminus j} \exp{\lambda_{k \to i,x_i}} \prod_{k \in \nei{j}\setminus i} \exp{\lambda_{k \to j,x_j}}
\eea
Which is exactly as \eqref{eq:bp_single_marginal} and \eqref{eq:bp_pairwise_marginal} when BP converges.
Hence, BP fix points are local minima of the Bethe energy.

This result give us some insight to the results BP may return and to how BP should be used.
As was written before, BP could have  more than one fix point.
This empirical fact has now have theoretical reasoning. 
Since local minima of the Bethe free energy is a stable fix point of BP.
The Bethe free energy is a non-convex function hence multiple minima may exist.
Hence BP may have multiple stable fix point.
Note that not all fix point have the same quality (at least regarding the solution of \eqref{eq:bethe_approximation}).
Two fix points where one have lower Bethe free energy should not be treated the same - the one of the lower energy could be a solution to \eqref{eq:bethe_approximation} while the other could not.
This imply against a common practice of initializing the massages $\boldsymbol{m}^0$ to uniform distribution and running BP only once.
The above imply that random initialization and multiple running of BP may improve the quality of BP results.

The connection between BP and the Bethe energy promote a wide research.
The research can be divided to three categories.
Extensions of BP, convergence of BP and bounding the error of BP.
I will now give short survey to each category.  

The most immediate extension to BP using the above, was the Generalized Belief Propagation \cite{yedidia2000generalized}. 
Instead of maximizing the Bethe energy it maximize the Kikuchi free energy - an extension from only pairwise interaction to larger areas.

One of the draw backs of the Bethe approximation is the fact that the Bethe entropy is not a concave function.
Tree Re-Weighted Belief Propagation (TRW) \cite{wainwright2003tree} suggest a surrogate entropy  which is concave.
This is done by giving weights to the information part (the second summation) in \eqref{eq:bethe_entorpy_information}.
It's name come from the interpretation of these weights.
The model parameter can be decomposed: $\thetav=\sum_{\mathfrak{t}} t_{\mathfrak{t}}\thetav^{\mathfrak{t}}$ such that each $\thetav^{\mathfrak{t}}$ is sub-model\footnote{$\theta^{\mathfrak{t}}_{ij}$ is either $0$ or $\theta_{ij}$ and $\theta^{\mathfrak{t}}_i =\theta_i$} which its structure is a tree, and $t_{\mathfrak{t}}\geq 0$, $\sum_{\mathfrak{t}} t_{\mathfrak{t}} = 1$.
Such probability induce a probability for each edge to appear in any one of the trees.
These probabilities are the weights of the information part.
This gave another advantage to TRW, the resulted log partition function is an upper bound to the true partition function. 
This easily can be seen by using Jensen inequality\footnote{Remember that the partition function is a convex function of $\thetav$.} $Z(\thetav) = Z\left(\sum_{\mathfrak{t}} t_{\mathfrak{t}}\thetav^{\mathfrak{t}}\right) \leq \sum_{\mathfrak{t}} t_{\mathfrak{t}} Z(\thetav^{\mathfrak{t}})$ which is exactly the TRW approximation to the partition function.
Both algorithms suggest a variation of BP messages to fit the change in energy.
A unify view of these two algorithm (and others) can be found in \cite{meshi2009convexifying}.

Another line of inference algorithm try to optimize the Bethe free energy directly.
For the binary case \cite{welling2001belief} and later \cite{shin2012complexity} give a similar algorithm but the later gave time complexity guaranties.
A general algorithm was given by \cite{yuille2002cccp} which use CCP\cite{yuille2002concave} to optimize the Bethe or Kikuchi energies.

One of the basic requirements of any algorithm is to know that after some time it will return a result.
In BP case, it mean that the messages will converges.
A model that BP does not converge on is easy to build.
so the question remain, can convergence be guaranteed under some model's constrains.
The first work to so was \cite{tatikonda2002loopy} where a bound on the pairwise interaction was given to insure convergence.
For proving the bound the computation tree of BP was used.
The computation tree, describe the running of BP where each time is a level in the tree.
The root value is the pseudo-marginal of specific vertex at time $t$ , its children are the neighbors that send it a message with values of the messages at time $t-1$.
It continue to go back at time, until the leaves which are the initial messages at time $0$.
Considering the time at infinity, If the marginals in time $t$ is independent of the initial messages at time $0$ BP will converge.
This method come from the physics world where it is called uniqueness of Gibbs measure or independence of boundary conditions.

In \cite{heskes2004uniqueness} the connection between Bethe and BP help us to find convergence guarantees.
Finding conditions that insure the convexity of Bethe energy, imply finding condition to the convergence of BP. 
For BP to converge,  the distance (in some measure) between the current messages and the previous one should get smaller and smaller.
If this change can be bound by a constant (strictly smaller than one) the convergence of BP can be guaranteed.
In both papers \cite{mooij2007sufficient}, \cite{roosta2008convergence} this intuition is used to provide bounds for BP convergence.
Note that all these method do not find conditions to BP convergence but that BP will have a single fix point.
This fact will be important in my paper \cite{heinemann2012cannot}.

The relation between the Bethe partition function and the exact is till an open question.
It is clear that a relation can not be given in the general case - it sometimes bigger and sometimes smaller than the exact partition function.
One of the first results was by \cite{AlanNips2007} that prove that if all the pseudo-marginals are in the same orientation (all bigger or smaller than $0.5$) the Bethe partition function lower bounds the exact partition function.
Later \cite{RuozziNips2012},  gave a stronger result, if the pairwise interaction are log sub-modular the Bethe partition function lower bound the exact partition function ( the case of attractive models is an instance of this class).
In their prove they used the important work of \cite{vontobel2013counting} that gave a combinatorial meaning to the Bethe entropy.

To conclude, the connection between BP and Bethe contribute to the understanding of BP and help improve it.
The biggest short coming of this connection is that it say nothing with respect to BP massages before conversion.
In contrast,  another interpretation of BP is seeing BP is re-parametrization algorithm that try to change the parametrization of $\thetav$ such that it will belong to the local-polytope.
For full proof please see \cite{wainwright2002stochastic}.

\ignore{
\be
\mu_k(x_k;\thetav) = \frac{1}{Z(\thetav)}\sum_{\substack{\xx \\
s.t.\  \xx_k=x_k}}e^{\theta_k(x_k) + \sum_{j \in \nei{k}}\theta_{k,j}(x_k,x_j)}e^{\sum_{i \in V \setminus k}\theta_{i}(x_i) +\sum_{\substack{ij \in E\\
 s.t.\  i,j \ne k}}\theta_{ij}(x_i,x_j)}
%} {\sum_{\hat{x}_k}e^{\theta_k(\hat{x}_k) + \sum_{j \in \nei{k}}\theta_{k,j}(\hat{x}_k,x_j)}e^{\sum_{i \in V \setminus k}\theta_{i}(x_i) +\sum_{\substack{ij \in E\\
% s.t.\  i,j \ne k}}\theta_{ij}(x_i,x_j)}}
\ee
Denote by $\thetav^{\setminus k}$ the model where we remove all factors involve the vertex $k$.
Now the marginal of the neighbors of $k$ in  that model is
\be
\muv_{\nei{k}}(\xx_{\nei{k}}; \thetav^{\setminus k}) \approx \sum_{\substack{\hat{\xx}\\
s.t. \hat{\xx}_{\nei{k}} = \xx_{\nei{k}}}}  e^{\sum_{i \in V \setminus k}\theta_{i}(\hat{x}_i) +\sum_{\substack{ij \in E\\
 s.t.\  i,j \ne k}}\theta_{ij}(\hat{x}_i,\hat{x}_j)}
\ee
 With this we can write
\bea
\mu_k(x_k;\thetav)  &\approx& \sum_{\xx_{\nei{k}}} e^{\theta_k(x_k) + \sum_{j \in \nei{k}}\theta_{k,j}(x_k,x_j)} \muv_{\nei{k}}(\xx_{\nei{k}}; \thetav^{\setminus k})\\
 &\approx& e^{\theta_k(x_k)}  \prod_{j \in \nei{k}} \sum_{ x_j } e^{\theta_{k,j}(x_k,x_j)} \muv_{j}(x_j; \thetav^{\setminus k})\\
\eea
}
\subsection{Sampling}
\label{sec:sampling}
Sampling in a first glance seem the perfect solution for finding the marginals.
The marginals can be estimated as the mean of bounded random variable.
Using Hoeffding bound the probability of mistake greater than $\epsilon$ can be bound by $P(|p(x_i) - \frac{\sum_{m=1}^M \deltaF{\xx_i^m=x_i}}{M}| > \epsilon) < 2\exp{-\frac{2\epsilon^2M}{|\cX|^2}}$.
This mean we have a time complexity of $O(\frac{\log(\delta) |\cX|^2}{\epsilon^2})$\footnote{With probability greater than $1-\delta$ the estimation error will be less than $\epsilon$}.
The problem in the above is, that sampling from a model as in \eqref{eq:ciluqe_prob} is hard in itself\footnote{This is easly be seen from redction to q-coloring for example \cite{levin2009markov,bordewich2016mixing}}.
So how can we sample.

Markov Chain Mote Carlo(MCMC) is a method to sample from a distribution $P(\xx)$ while have the ability to sample only from distribution $Q(\xx)$.
The idea is as follow, build a Markov chain with two main features.
The first, it must be easy to move from one state to another.
The second, the stationary distribution of the Markov chain is $P(\xx)$.

To define Markov chain one need to define the transition matrix between any two states.
In MCMC it is a matrix of dimension $A \in [0,1]^{|\cX|^{p},|\cX|^{p}}$ where each row sum to one $\sum_j A_{i,j} = 1$.
The stationary distribution is a distribution to be on a state that satisfy $A\vv=\vv$.
The distribution needed to be sampled should be the stationary distribution for the MCMC.


Metropolis chains is an example how the Markov chain can be built.
The transition matrix is defined as follow
\be
A(\xx,\tilde{\xx}) = \left\{
\begin{array}{lr}
Q(\tilde{\xx}|\xx)\min\{1,\frac{Q(\xx|\tilde{\xx})P(\tilde{\xx})}{Q(\tilde{\xx}|\xx)P(\xx)}\} & \tilde{\xx} \neq \xx\\
1 - \sum_{\hat{\xx} \neq \xx} Q(\hat{\xx}|\xx)\min\{1,\frac{Q(\xx|\hat{\xx})P(\hat{\xx})}{Q(\hat{\xx}|\xx)P(\xx)}\} & \text{else}
\end{array} \right.
\ee
Note that $Q(\xx|\tilde{\xx})$ must only be irreducible\footnote{Irreducible defined by, for  all $\xx,\xx_0 \in \cX^p$ exists $k \in \naturalNumbers$ and $\xx^1, \ldots, \xx^k=\xx$ such that $\prod_{i=1}^k Q(\xx_i|\xx_{i-1}) >0$} - it not necessarily be symmetric.
Hence it could be the distribution over a tree or any easy to sample distribution.
Moreover, we only need to compute $\frac{P(\xx)}{P(\tilde{\xx})} $ hence the partition function canceled and the quantity is easy to calculate.

Glauber chains or Gibbs sampler is another method to define the Markov transition matrix.
The idea is simple, in each iteration only a small number of variables will change, denote this group by $\cI \subseteq [1,\ldots,p]$, $|\cI| = k$.
Than the possible next states are the ones that differ from the current state $\xx$ only in the indices in $\cI$.
Denote this set by $\mathcal{D}(\xx,\cI) = \left\{\tilde{\xx} \in \cX^p | \forall i \notin \cI,\ \xx_i = \tilde{\xx}_i \right\}$.
The set $\mathcal{D}^k(\xx)= \cup_{\cI, |\cI|=k} \mathcal{D}(\xx,\cI)$ denotes the set of all $\tilde{\xx}$ that differ from $\xx$ only in $k$ entries.
Now the transition matrix is defined as,
\be
A(\xx,\tilde{\xx}) = \left\{
\begin{array}{lr}
0 & \tilde{\xx} \notin \mathcal{D}^k(\xx)\\
\frac{(p-k)!k!}{p!}\frac{P(\tilde{\xx})}{\sum_{\hat{\xx} \in \mathcal{D}(\xx,\cI)}P(\hat{\xx})} & \tilde{\xx} \in \mathcal{D}^k(\xx), \xx \neq \tilde{\xx}\\
\frac{(p-k)!k!}{p!}\sum_{\cI, |\cI|=k}\frac{P(\xx)}{\sum_{\hat{\xx} \in \mathcal{D}(\xx,\cI)}P(\hat{\xx})}& \xx = \tilde{\xx}
\end{array} \right.
\ee
Note that as in the above case We only need to compute the ratio of $P(\xx)$ hence the partition function can be canceled.

The remain question giving an arbitrary $\xx$ start state how fast are we guaranteed to sample from the stationary distribution.
This constant is called the \textit{mixing time}.
The mixing time is defined as the maximum number of moves needed to take until reaching the stationary distribution while starting from any distribution.
\be
\tau_{\epsilon}  = \min_{\tau \in \naturalNumbers}\sup_{\vv \in \Omega} \left\{\tau | d\left(A^{\tau}\vv,P(\xx)\right) < \epsilon\right\}
\ee
where $\Omega = \{ \vv \in [0,1]^{|\cX|^{p}} | \sum_i \vv_i = 1\}$, and $d(\vv,\tilde{\vv})$ is any distance function between probabilities.\footnote{ From the above condition it is easy to see the connection to the spectral gap (the distance between the largest to the second eigenvalue) and the mixing time. For more information see\cite{levin2009markov}}  .
The mixing time depend on the model features such as interaction strength,  dependency structure etc.
Hence models with small mixing time can be easily be sampled, inferring the marginals is doable.
This fact will be important when taking about inferning\ref{}.    

