% !TEX root =../main.tex
\subsection{Approximate inference}
\label{sec:approx}
Graphical models is a powerful tool.
In order it to be of use, an algorithm should be found that could answer queries based on the model, in other words preform inference.
As written above, exact inference in the general is NP-complete.
Hence the importance of finding an approximate inference.
I will focus in this introduction only on the problem of finding the marginals (not the MAP problem) since in learning it is of more use as I will show later.

The approximate inference algorithm can be divided in to two main categories: variational inference, and sampling.
I will now try to go over the main principles of the two categories.
\subsection{Variational Methods}
\label{sec:variational_methods}
I will follow in this section the excellent work by \cite{wainwright2008graphical}.
The goal of the inference is to find $\muv$ the model marginals.
Hence the first thing to define is the space of $\muv$ - the marginal-ploytope $\margpoly^G$.
\be
\label{eq:margpoly}
\margpoly^G = \left\{ \muv \in [0,1]^d\ \left| 
\begin{array}{lr}
  \exists \thetav \in \Omega^G\ s.t. \\
  \forall i \in V \land \forall x_i \in \cX &   P(x_i;\thetav) = \mu_i(x_i)\\
  \forall ij \in E \land \forall x_i, x_j \in \cX &P(x_i,x_j;\thetav) = \mu_{ij}(x_i,x_j)
\end{array} \right. \right\}
\ee
Having this the conjugate dual of the log partition function could be defined
\be
\label{eq:conjugate_partition}
A^*(\muv) = \sup_{\thetav \in \Omega^G} \left\{\muv \cdot \thetav - A(\thetav)\right\}
\ee
Two things should be noted. The first is that if $\muv \in \margpoly^G$\footnote{This imply only for marginals in the inner part of the marginal polytope. For marginals on the boundaries more delicate treatment should be given} than $A^*(\muv) = -H(P(\xx;\thetav(\muv)))$ the conjugate of the log partition function is equals to the entropy of the probability that its marginals are $\muv$.
Second,  \eqref{eq:conjugate_partition} is similar to the maximum likelihood objective (see \secref{sec:max_likelihood}).
It can be shown that $A(\thetav)$ is a convex function of $\thetav$ which lead to ${A^{*}}^* = A$, having that the variational expression of $A(\thetav)$ can be written as, 
\bean
A(\thetav) &=& \sup_{\muv \in \margpoly^G}\left \{ \muv \cdot \thetav + H(P(\xx;\thetav(\muv))) \right\} \label{eq:variation_A} \\
\muv^{\thetav}&=& \arg \sup_{\muv \in \margpoly^G}\left \{ \muv \cdot \thetav + H(P(\xx;\thetav(\muv))) \right\} \label{eq:arg_variation_A}
\eean
\eqref{eq:arg_variation_A} and \eqref{eq:variation_A} present a new way to infer the marginals and calculate the partition function.
Not surprisingly, solving this optimization is hard in itself for two reasons.
The first, the marginal-polytope is a very complex  body - its description is exponential in $d$ the size of $\muv$.
The second, calculating the entropy is a hard problem by itself.
The merit in this representation, is the ability to approximate these two quantities - the entropy and the marginal polytope.

I will present two method of approximation, the first limit both the marginal-polytope and the entropy to a sub-graph of $G$ in a way that both are easy to calculate - the mean-field method \cite{peterson1987mean}.
The second method give different approximation to the entropy and marginal polytope.
For example, the local polytope (defined in \eqref{eq:local_polytope}) will approximate the marginal-polytope, while the entropy is approximated by the Bethe-entropy. 
The resulted approximation is the  Bethe approximation which is related to the known algorithm Belief-Propagation\cite{pearl1986fusion, yedidia2000generalized}.
\subsubsection{Mean Field}
Mean field is a technique that approximate a complex model by a simpler one.
%In inference, it approximate the real model marginals by marginals of a simpler model.
More specifically, it replace the marginal polytope (of the true dependencies graph) and the true entropy, with marginal polytope and entropy of simpler dependencies graph.
I will illustrate this technique by choosing the simplest graph - the independent graph denote by $G_I$.
In this case, the marginal polytope sum down to,
\be
\label{eq:margpoly}
\margpoly^{G_I} = \left\{\muv \in \Re^{d}\left|
\begin{array}{lr}
\forall i \in V,\ \forall x_i \in \cX & 0\leq \mu_i(x_i)\\
\forall i \in V & \sum_{x \in \cX} \mu_i(x_i) = 1\\
\forall ij \in G,\ x_i,x_j \in \cX & \mu_{ij}(x_i,x_j) = \mu_i(x_i)\mu_j(x_j)
\end{array}
\right.\right\}
\ee
Note that the dimension of the marginals is with respect to the original graph,
moreover, $\margpoly^{G_I} \subseteq \margpoly^{G}$\footnote{Note that marginals that correspond to the pairwise interaction are constrain to reflect independence a constrain that does not exist in the original marginal polytope.}.\\
Now the entropy for this family of models is simple,
\be
H_{G_I}(\muv) = -\sum_{i}\sum_{x_i} \mu_i(x_i)\log\mu_i(x_i)
\ee 
So the partition function can be written as
\be
A_{G_I}(\thetav) = \sup_{\muv \in \margpoly^{G_I}}\left \{ \muv \cdot \thetav + H_{G_I}(\muv))) \right\} \label{eq:naive_mean_field} \\
\ee
Note that $A(\thetav) \geq A_{G_I}(\thetav)$ since by restricting the marginal polytope the result can only decrease (the entropy is exact on this models family).
Taking the derivative of the right side of \eqref{eq:naive_mean_field} and comparing to zero gives
\be
\mu_i(x_i) \propto \exp{\theta_i(x_i) + \sum_{j\in \nei{i}} \sum_{x_j} \theta_{ij}(x_i,x_j)\mu_j(x_j) } \label{eq:naive_iter}
\ee
Iterating through \eqref{eq:naive_iter} will converge since \eqref{eq:naive_mean_field} is a concave function.

The above example demonstrate two important feature of the chosen dependency graph.
First, the entropy should be easy to calculate.
Second, the resulted approximated variational equation should be convex - easy to optimized.
The second feature does not always hold, for example if the dependency graph is a tree. 
The model entropy is the Bethe entropy (see \eqref{eq:bethe_entropy}) which is not a concave function. 
Hence, local maximum could occur and the resulted algorithm may not converge\footnote{ This is not BP, to get BP the optimization should be over the local polytope not the tree polytope}.
This lead as to the next approach - different approximation to the marginal polytope and entropy.
\subsubsection{Belief Propagation}
\label{sec:belief}
Belief-Propagation (BP) is a message passing algorithm.
In each cycle\footnote{The order of the messages can effect convergence rate see for example \cite{elidan2012residual}.} a message is passed from a vertex to all its neighbors.
The message reflect the source vertex belief on the destination vertex probability.
The message is a function of the factor connecting the two vertices and the messages from all neighbors except the destination neighbor.
BP continue to cycle until the difference in the messages is very small or after a fix number of cycles.
The messages can be written as, 
\be
\label{eq:belief_propagation}
m_{i \to j}^{t}(x_j) \propto \sum_{x_i \in\cX} \exp{\theta_{i,j}(x_i,x_j)+\theta_{i}(x_i)}\prod_{k \in \nei{i} \setminus j } m_{k \to i}^{t-1} (x_i)
\ee 
While resulted pseudo-marginals are calculated by,
\bean
\tau_i(x_i) &\propto& \exp{\theta_i(x_i)} \prod_{k \in \nei{i}} m^T_{k \to i}(x_i) \label{eq:bp_single_marginal}\\
\tau_{ij}(x_i,x_j) &\propto& \exp{\theta_{ij}(x_i,x_j)+\theta_i(x_i)+\theta_j(x_j)} \prod_{k \in \nei{i}\setminus j} m_{k \to i}^{T} (x_i) \prod_{k \in \nei{j}\setminus i}m_{k \to j}^{T} (x_j)\label{eq:bp_pairwise_marginal}
\eean

BP is exact when the dependency graph is a tree - the pseudo-marginals are the exact marginals $\tauv^{\thetav} = \muv^{\thetav}$.
There are other models families  where the error of BP marginals can be bound\footnote{Tree-like model is an example of such family\cite{dembo2010ising}, this fact is used in my second paper\cite{heinemann2014inferning}.}. 
But in the general case the quality of the pseudo-marginals is unknown. 
Moreover, there are cases where BP does not converge and even when it does the resulted pseudo-marginals may depend on the initial messages $\boldsymbol{m}^0$.
Despite the above BP give good results in practice \cite{willsky2002multiresolution,loeliger2004introduction,kschischang2003codes}.

The first step in understanding BP is to give meaning to the resulted pseudo-marginals.
This was done by \cite{yedidia2000generalized, yedidia2003understanding} they found that the fix point of BP are local minima of the Bethe free energy of the system\footnote{Later \cite{heskes2002stable} refined this result to \textbf{stable} fix point of BP are  local minima of the Bethe approximation}.
Not only that this result gave meaning to BP fix points, it allow theoretical analysis of BP. 
I will now present this result but before that we need some definitions.

As mention earlier, the approximation of \eqref{eq:variation_A} include two parts:
first lets defined the Bethe entropy - an approximation of the true entropy,
\bean
H_B(\tauv) &=& -\sum_{i} (1-d_i)\sum_{x_i}\tau_i(x_i)\log\tau_i(x_i) -\sum_{ij}\sum_{x_i,x_j}\tau_{ij}(x_i,x_j)\log\tau_{ij}(x_i,x_j)\label{eq:bethe_entropy}\\
&=&-\sum_{i}\sum_{x_i}\tau_i(x_i)\log\tau_i(x_i) -\sum_{ij}\sum_{x_i,x_j}\tau_{ij}(x_i,x_j)\log\frac{\tau_{ij}(x_i,x_j)}{\tau_i(x_i)\tau_j(x_j)} \label{eq:bethe_entorpy_information}
\eean
Second  the approximation of the marginal-polytope with the local-polytope.
\be
\label{eq:local_polytope}
\lclmargpoly = \left\{\tauv \in \Re^d\left| 
\begin{array}{lr}
\forall i \in V & \sum_{x_i} \tau_i(x_i) = 1\\
\forall i \in V, \forall x_i \in \cX,\ \forall j \in \nei{j}& \sum_{x_j}\tau_{ij}(x_i,x_j) = \tau_i(x_i)\\
\forall i \in V,\ \forall ij \in E,\ x_i,x_j \in \cX &\tau_{ij}(x_i,x_j) \geq 0% \tau_i(x_i) \geq 0,\ 
\end{array}\right.\right\}
\ee 
We are now able to write the Bethe approximation to the partition function.
\be
\label{eq:bethe_approximation}
A_B(\thetav) = \sup_{\tauv \in \lclmargpoly} \left\{\thetav \cdot \tauv + H_B(\tauv)\right\}
\ee
And the Bethe energy is $-A_B(\thetav)$.\\
In contrast to the variational free energy, the Bethe free energy is simple to calculate, since the local polytope is describe by a linear number of  constrains and the Bethe entropy calculation is straight forward .
This however come with a price.
First the result does not necessarily belong to the marginal-polytope hence not a ``real'' marginal.
Second, the resulted optimization is no longer convex - the Bethe entropy is non-convex function while the true one is convex.
Hence the complexity of optimizing this objective is not clear - I am not aware on any result on the time complexity of Bethe approximation\footnote{In \cite{weller2012bethe} a polynomial algorithm is suggested that approximate the Bethe free energy up to arbitrary precision under some models constrains.}.

We can now quote \cite{yedidia2000generalized} claim:
\begin{claim}
\label{thm:bp_bethe}
Let  $\mm$ be a set of messages as in \eqref{eq:belief_propagation} and let $\tauv$ be the calculated pseudo-marginal as in \eqref{eq:bp_pairwise_marginal}.
Than the pseudo-marginal are fix-point of BP if and only if they are zero gradient points of the Bethe Free energy \eqref{eq:bethe_approximation}.
\end{claim}
%So the importance of \eqref{eq:bethe_approximation} to inference, is its connection to BP.

The proof is very simple, writing the Lagrangian of this optimization,
\bea
\mathcal{L}(\thetav,\tauv,\lambdav) &=& -\thetav \cdot \tauv - H_B(\tauv) \\
&+& \sum_i \lambda_i \left(1-\sum_{x_i} \tau_i(x_i)\right) + \sum_{i} \sum_{j \in \nei{i}}\sum_{x_i}\lambda_{j \to i, x_i}\left(\tau_i(x_i)-\sum_{x_j} \tau_{ij}(x_i,x_j)\right)
\eea
Using \eqref{eq:bethe_entorpy_information} for the Bethe entropy and remembering the derivative of $x\log\frac{x}{a}$ is $\log\frac{x}{a}+1$ the derivatives compare to zero give\footnote{And using the constrain $\sum_{x_i}\tau_{ij}(x_i,x_j) = \tau_j(x_j)$},
\bea
\log{\tau_i(x_i)} &=& \theta_i(x_i)+ \sum_{j \in \nei{i}} \lambda_{j \to i,x_i}-(d_i-1)+\lambda_i\\
\log{\tau_{ij}(x_i,x_j)} &=&  \theta_{ij}(x_i,x_j) - \lambda_{j \to i,x_i} -  \lambda_{i \to j,x_j} +\log \tau_{i}(x_i) +\log \tau_{j}(x_j) -1
%\frac{\partial \mathcal{L}(\thetav,\tauv,\lambdav)}{\partial \tau_i(x_i)} &=& \theta_i(x_i) - \log{\tau_i(x_i)}-1 - \sum_{j \in \nei{i}} \lambda_{i \to j,x_i}\\
%\frac{\partial \mathcal{L}(\thetav,\tauv,\lambdav)}{\partial \tau_{ij}(x_i,x_j)} &=& \theta_{ij}(x_i,x_j) + \log{\tau_{ij}(x_i,x_j)} + 1 + \lambda_{i \to j,x_i} + \lambda_{j \to i,x_j}
\eea
taking the exponent and rearranging\footnote{$\lambda_i$ are part of the normalization a long with the constants.} we have,
\bea
\tau_i(x_i) &\propto& \exp{\theta_i(x_i)}\prod_{j \in \nei{i}} \exp{\lambda_{j \to i,x_i}}\\
\tau_{ij}(x_i,x_j) &\propto&  \exp{\theta_{ij}(x_i,x_j)+\theta_i(x_i)+\theta_j(x_j)} \prod_{k \in \nei{i}\setminus j} \exp{\lambda_{k \to i,x_i}} \prod_{k \in \nei{j}\setminus i} \exp{\lambda_{k \to j,x_j}}
\eea
Which is exactly as \eqref{eq:bp_single_marginal} and \eqref{eq:bp_pairwise_marginal} when BP converges.
Hence, BP fix points are local minima of the Bethe energy.

\claimref{thm:bp_bethe} promote a wide research.
The research can be divided to three categories.
Extensions of BP, convergence of BP and bounding the error of BP.
I will now give short survey to each category but will start with simple implication of this claim.

As was written before, BP could have  more than one fix point.
This empirical fact has now have theoretical reasoning. 
\claimref{thm:bp_bethe} state that local minima of the Bethe free energy is a stable fix point of BP.
Adding the fact that the Bethe free energy is a non-convex function result in multiple minima may exist - BP may have more than one fix point.
Note that not all fix point have the same quality (at least regarding the solution of \eqref{eq:bethe_approximation}).
Two fix points where one have lower Bethe free energy should not be treated the same - the one of the lower energy could be a solution to \eqref{eq:bethe_approximation} while the other could not.
This imply against a common practice of initializing the massages $\boldsymbol{m}^0$ to uniform distribution and running BP only once.
Multiple running of BP with random initialization may improve the quality of BP results (at least when calculating partition function)\footnote{How to use the resulted pseudo-marginals of BP when multiple maximum exist can be an interesting research direction.}.

The most immediate extension to BP using \claimref{thm:bp_bethe}, was the Generalized Belief Propagation \cite{yedidia2000generalized}. 
Instead of maximizing the Bethe energy it maximize the Kikuchi free energy - an extension from only pairwise interaction to larger areas.
One of the draw backs of the Bethe approximation is the fact that the Bethe entropy is not a concave function.
Tree Re-Weighted Belief Propagation (TRW) \cite{wainwright2003tree} suggest a surrogate entropy  which is concave.
This is done by giving weights to the information part (the second summation) in \eqref{eq:bethe_entorpy_information}.
It's name come from the interpretation of these weights.
The model parameter can be decomposed: $\thetav=\sum_{\mathfrak{t}} t_{\mathfrak{t}}\thetav^{\mathfrak{t}}$ such that each $\thetav^{\mathfrak{t}}$ is sub-model\footnote{$\theta^{\mathfrak{t}}_{ij}$ is either $0$ or $\theta_{ij}$ and $\theta^{\mathfrak{t}}_i =\theta_i$} which its structure is a tree, and $t_{\mathfrak{t}}\geq 0$, $\sum_{\mathfrak{t}} t_{\mathfrak{t}} = 1$.
The probability on trees induce a probability for each edge to appear in any one of the trees.
These probabilities are  weights of the information part.
This gave another advantage to TRW, the resulted log partition function is an upper bound to the true partition function. 
This easily can be seen by using Jensen inequality\footnote{Remember that the partition function is a convex function of $\thetav$.} $Z(\thetav) = Z\left(\sum_{\mathfrak{t}} t_{\mathfrak{t}}\thetav^{\mathfrak{t}}\right) \leq \sum_{\mathfrak{t}} t_{\mathfrak{t}} Z(\thetav^{\mathfrak{t}})$ which is exactly the TRW approximation to the partition function.
Both algorithms suggest a variation of BP messages to fit the change in energy.
A unify view of these two algorithm (and others) can be found in \cite{meshi2009convexifying}.

Another line of inference algorithm try to optimize the Bethe free energy directly.
For the binary case \cite{welling2001belief} and later \cite{shin2012complexity} give a similar algorithm but the later gave time complexity guaranties.
A general algorithm was given by \cite{yuille2002cccp} which use CCP\cite{yuille2002concave} to optimize the Bethe or Kikuchi energies.

One of the basic requirements of any algorithm is to know that after some time it will return a result.
In BP case, it means that the messages will converges.
Since a model that BP does not converge on is easy to build, for BP this translate in to finding model constrains that guarantee BP convergence. 
%So the question remain, can convergence be guaranteed under some model's constrains.
The first work to do so was \cite{tatikonda2002loopy} where a bound on the pairwise interaction was given to insure convergence.
For proving the bound the computation tree of BP was used.
The computation tree, describe the running of BP where each time is a level in the tree.
The root value is the pseudo-marginal of specific vertex at time $t$ , its children are the neighbors that send it a message $t-1$ their values are the pseudo-marginal at that time.
It continue to go back at time, until the leaves which are the initial messages at time $0$.
Taking the time to infinity, If the marginals in time $t$ is independent of the initial messages at time $0$ BP will converge.
This method come from the physics world where it is called uniqueness of Gibbs measure or independence of boundary conditions\footnote{These notion are important to understanding our second paper \cite{heinemann2014inferning} where each marginals should be independent of nodes in distance $l$.}.

\claimref{thm:bp_bethe} is used in \cite{heskes2004uniqueness} for finding convergence guarantees.
Since insuring the convexity of Bethe energy imply convergence of BP.
They define a set of condition that guarantee the convexity of the Bethe free energy.
Another method to guarantee BP convergence,  is the ability to bound the speed in which the messages get closer to each other.
In other words, if the rate in which the distance (in some measure) between the current messages and the previous one can be bound by a constant (strictly smaller than one) than convergence of BP can be guaranteed.
In both papers \cite{mooij2007sufficient}, \cite{roosta2008convergence} this intuition is used to provide bounds for BP convergence.
Note that all these method do not find conditions to BP convergence but that BP will have a single fix point.
This fact will be important in my paper \cite{heinemann2012cannot}.

The relation between the Bethe partition function \eqref{eq:bethe_approximation} and the exact one \eqref{eq:variation_A} is till an open question.
It is clear that a relation can not be given in the general case - The Bethe approximation is sometimes bigger and sometimes smaller than the exact partition function.
One of the first results was by \cite{AlanNips2007} that prove that if all the pseudo-marginals are in the same orientation (all bigger or smaller than $0.5$) the Bethe partition function lower bounds the exact partition function.
Later \cite{RuozziNips2012},  gave a stronger result, if the pairwise interaction are log sub-modular the Bethe partition function lower bound the exact partition function ( the case of attractive models is an instance of this class).
In their prove they used the important work of \cite{vontobel2013counting} that gave a combinatorial meaning to the Bethe entropy.

To conclude, the connection between BP and Bethe contribute to the understanding of BP and help improve it.
The biggest short coming of this connection is that it say nothing with respect to BP massages before conversion.
In contrast,  another interpretation of BP is seeing BP is re-parametrization algorithm that try to change the parametrization of $\thetav$ such that it will belong to the local-polytope.
For full proof please see \cite{wainwright2002stochastic}.
\ignore{
\be
\mu_k(x_k;\thetav) = \frac{1}{Z(\thetav)}\sum_{\substack{\xx \\
s.t.\  \xx_k=x_k}}e^{\theta_k(x_k) + \sum_{j \in \nei{k}}\theta_{k,j}(x_k,x_j)}e^{\sum_{i \in V \setminus k}\theta_{i}(x_i) +\sum_{\substack{ij \in E\\
 s.t.\  i,j \ne k}}\theta_{ij}(x_i,x_j)}
%} {\sum_{\hat{x}_k}e^{\theta_k(\hat{x}_k) + \sum_{j \in \nei{k}}\theta_{k,j}(\hat{x}_k,x_j)}e^{\sum_{i \in V \setminus k}\theta_{i}(x_i) +\sum_{\substack{ij \in E\\
% s.t.\  i,j \ne k}}\theta_{ij}(x_i,x_j)}}
\ee
Denote by $\thetav^{\setminus k}$ the model where we remove all factors involve the vertex $k$.
Now the marginal of the neighbors of $k$ in  that model is
\be
\muv_{\nei{k}}(\xx_{\nei{k}}; \thetav^{\setminus k}) \approx \sum_{\substack{\hat{\xx}\\
s.t. \hat{\xx}_{\nei{k}} = \xx_{\nei{k}}}}  e^{\sum_{i \in V \setminus k}\theta_{i}(\hat{x}_i) +\sum_{\substack{ij \in E\\
 s.t.\  i,j \ne k}}\theta_{ij}(\hat{x}_i,\hat{x}_j)}
\ee
 With this we can write
\bea
\mu_k(x_k;\thetav)  &\approx& \sum_{\xx_{\nei{k}}} e^{\theta_k(x_k) + \sum_{j \in \nei{k}}\theta_{k,j}(x_k,x_j)} \muv_{\nei{k}}(\xx_{\nei{k}}; \thetav^{\setminus k})\\
 &\approx& e^{\theta_k(x_k)}  \prod_{j \in \nei{k}} \sum_{ x_j } e^{\theta_{k,j}(x_k,x_j)} \muv_{j}(x_j; \thetav^{\setminus k})\\
\eea
}
\subsection{Sampling}
\label{sec:sampling}
Sampling in a first glance seem the perfect solution for finding the marginals.
The marginals can be estimated as the mean of bounded random variable.
Using Hoeffding bound the probability of mistake greater than $\epsilon$ can be bound by $P(|p(x_i) - \frac{\sum_{m=1}^M \deltaF{\xx_i^m=x_i}}{M}| > \epsilon) < 2\exp{-\frac{2\epsilon^2M}{|\cX|^2}}$.
This mean we have a time complexity of $O(\frac{\log(\delta) |\cX|^2}{\epsilon^2})$\footnote{With probability greater than $1-\delta$ the estimation error will be less than $\epsilon$}.
The problem in the above is, that sampling from a model as in \eqref{eq:ciluqe_prob} is hard in itself\footnote{This is easly be seen from redction to q-coloring for example \cite{levin2009markov,bordewich2016mixing}}.
So how can we sample.

Markov Chain Mote Carlo(MCMC) is a method to sample from a distribution $P(\xx)$ while have the ability to sample only from distribution $Q(\xx)$.
The idea is as follow, build a Markov chain with two main features.
The first, it must be easy to move from one state to another.
The second, the stationary distribution of the Markov chain is $P(\xx)$.

To define a Markov chain one need to define the transition matrix between any two states.
The matrix rows should sum to one $\sum_j A_{i,j} = 1$ and the coordinate $A_{i,j}$ define the probability to move from  state $i$ to state $j$.
In MCMC this matrix of dimensions are $A \in [0,1]^{|\cX|^{p},|\cX|^{p}}$ which mean that each state is full assignment of the model variables. 
The stationary distribution $\vv$ is a distribution over the states (over different assignment) that satisfy $A\vv=\vv$.
In MCMC this distribution should be $P(\xx)$ the model distribution.

Metropolis chains is an example of how the Markov chain can be built.
The transition matrix is defined as follow
\be
A(\xx,\tilde{\xx}) = \left\{
\begin{array}{lr}
Q(\tilde{\xx}|\xx)\min\{1,\frac{Q(\xx|\tilde{\xx})P(\tilde{\xx})}{Q(\tilde{\xx}|\xx)P(\xx)}\} & \tilde{\xx} \neq \xx\\
1 - \sum_{\hat{\xx} \neq \xx} Q(\hat{\xx}|\xx)\min\{1,\frac{Q(\xx|\hat{\xx})P(\hat{\xx})}{Q(\hat{\xx}|\xx)P(\xx)}\} & \text{else}
\end{array} \right.
\ee
Note that $Q(\xx|\tilde{\xx})$ must only be irreducible\footnote{Irreducible defined by, for  all $\xx,\xx_0 \in \cX^p$ exists $k \in \naturalNumbers$ and $\xx^1, \ldots, \xx^k=\xx$ such that $\prod_{i=1}^k Q(\xx_i|\xx_{i-1}) >0$} - it not necessarily be symmetric.
Hence it could be the distribution over a tree or any easy to sample distribution.
Moreover, we only need to compute $\frac{P(\xx)}{P(\tilde{\xx})} $ hence the partition function canceled and the quantity is easy to calculate.

Glauber chains or Gibbs sampler is another method to define the Markov transition matrix.
The idea is simple, in each iteration only a small number of variables will change, denote this group by $\cI \subseteq [1,\ldots,p]$, $|\cI| = k$.
Than the possible next states are the ones that differ from the current state $\xx$ only in the indices in $\cI$.
Denote this set by $\mathcal{D}(\xx,\cI) = \left\{\tilde{\xx} \in \cX^p | \forall i \notin \cI,\ \xx_i = \tilde{\xx}_i \right\}$.
The set $\mathcal{D}^k(\xx)= \cup_{\cI, |\cI|=k} \mathcal{D}(\xx,\cI)$ denotes the set of all $\tilde{\xx}$ that differ from $\xx$ only in $k$ entries.
Now the transition matrix is defined as,
\be
A(\xx,\tilde{\xx}) = \left\{
\begin{array}{lr}
0 & \tilde{\xx} \notin \mathcal{D}^k(\xx)\\
\frac{(p-k)!k!}{p!}\frac{P(\tilde{\xx})}{\sum_{\hat{\xx} \in \mathcal{D}(\xx,\cI)}P(\hat{\xx})} & \tilde{\xx} \in \mathcal{D}^k(\xx), \xx \neq \tilde{\xx}\\
\frac{(p-k)!k!}{p!}\sum_{\cI, |\cI|=k}\frac{P(\xx)}{\sum_{\hat{\xx} \in \mathcal{D}(\xx,\cI)}P(\hat{\xx})}& \xx = \tilde{\xx}
\end{array} \right.
\ee
Note that as in the above case We only need to compute the ratio of $P(\xx)$ hence the partition function can be canceled.

The remaining question is, how fast are we guaranteed to sample from the stationary distribution when starting from  an arbitrary assignment $\xx$.
This constant is called the \textit{mixing time}.
The mixing time is defined as the maximum number of moves (transitions between states) needed to be done until the visited states distribution is $\epsilon$ close to the stationary distribution while starting from any state.
\be
\tau_{\epsilon}  = \min_{\tau \in \naturalNumbers}\sup_{\vv \in \Omega} \left\{\tau | d\left(A^{\tau}\vv,P(\xx)\right) < \epsilon\right\}
\ee
where $\Omega = \{ \vv \in [0,1]^{|\cX|^{p}} | \sum_i \vv_i = 1\}$, and $d(\vv,\tilde{\vv})$ is any distance function between probabilities.\footnote{ From the above condition it is easy to see the connection to the spectral gap (the distance between the largest to the second eigenvalue) and the mixing time. For more information see\cite{levin2009markov}}  .
The mixing time depend on the model features such as interaction strength,  dependency structure etc.
Hence models with small mixing time can be easily be sampled - inferring the marginals is doable.
This fact will be important when taking about inferning \secref{sec:inferning}.

The next section cover learning graphical models.

