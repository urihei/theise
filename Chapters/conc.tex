% !TEX root =../main.tex
\chapter{Conclusion and Discussion } % Main chapter title
\label{con} % For referencing the chapter elsewhere, use \ref{con}
  Learning is usually achieved by selecting a group of models - selecting an hypothesis class and then finding the best model in this class.
  In some cases this paradigm is sub-optimal.
  For example in graphical models, the common approach to learning parameters is to use gradient descent for maximizing the likelihood.
  This, however, ignores the fact that approximate inference is used to find the gradient, which are the model marginals in this case.
  In the first paper, we show the implications of using BP as the approximate inference engine. Another weak point of this scheme is the definition of the ``best'' model. The most likely model (the model that optimizes ML) is the usual choice in graphical models. However, in many cases we are not interested in the model itself, but rather in its use for inference. Hence, the definition of ``best'' must take this into account, being the motivation for the second paper.

Selecting a correct hypothesis class is a crucial step in the learning
process.  A good hypothesis class is one that has sufficient expressive
power to model complex functions - but not too much as to suffer from
over-fitting. Another desirable property, is of course that learning can be done efficiently.  In the third paper, I consider the hypothesis class of deep networks, and explore an approach for making learning efficient in this case.

I will next provide a brief summary for each of these papers.

\ignore{
  Learning usually attempts to find the exact model.
  This translates into finding the model that minimizes some empirical loss out of some hypothesis class.
  In this thesis I was trying to understand the implication diverting from this scheme.
  The first paper goal is to understand the implication of changing the loss from the exact likelihood to the Bethe likelihood.
  Models are learned for use, hence the objective should optimize the quality of the use.
  In GM this is usually not the case.
  %The quality of the use is not part of the above objective.
  The second paper present a learning algorithm that can guarantee the quality of using the learned model.
  Choosing a correct hypothesis class is a crucial choice in the learning process.
  A good hypothesis class has enough expressive power to model complex function while not too much to reach over-fitting.
  Another quality, that sometimes set aside, is that it could be learned efficiently.
  In the third paper, the deep networks  hypothesis class, that proved to have the first quality, is extend to allow efficient learning.
  I will now give a short summery for each of the papers.
The title of this thesis ``Learning Using Approximate Inference'',\atodo{Is this the title?}  addresses two practical aspects of using complex graphical models. First, parameter learning in these models typically involves approximations (due to intractability of partition functions and marginals). Second, after learning, when the models are used to answer new queries, approximate inference is typically used. It is thus natural to study the manner in which these two steps interact, and this is indeed the goal of the first two chapters of this thesis. 
}

The first paper, presented in \secref{sec:lwbethe}, clarifies the implication of using loopy belief propagation (BP) as the approximate inference method during the learning process. We focus on the task of moment matching, and show that it is closely related to maximizing the Bethe likelihood (an approximation to the true likelihood). Our surprising finding is that even though Bethe likelihood is concave, its maximization does not necessarily result in moment matching. In fact, a more radical conclusion arises. Namely, that some moments can simply not be attained using belief propagation.  

Following the above insight, we characterize marginals where moment matching is and is not possible when learning with BP.  Specifically, we provide outer and inner bounds on these for some cases. It is an interesting theoretical challenge to provide further characterizations of this type, which will help understand when BP is likely to work well in the context of learning and inference.


\ignore{
More specifically, we define a set of marginals that could safely be learned by Bethe ML.
Furthermore, for empirical marginals in this set, we show that the canonical parameters \eqref{eq:canonical} maximize the Bethe ML, and no gradient descent is needed;
while for marginals outside this set, there are no parameters guaranteeing moment-matching \eqref{eq:moment_matching}, translating into parameters of questionable use.
We give an inner and outer bound for this set.
The existence of outer bounds to this set, which cross the marginal polytope, prove the existence of marginals that will never be a sole fix point of BP, or even a stable fix point at all.
}

Our second paper in \secref{sec:lg} addresses the ``inferning'' setup, where loopy belief propagation is used as an inference algorithm for answering queries after learning.  
%Remembering the fact that the quality of the learning process is asses by the quality of the results of the approximate inference and not by how close the model is to the real one.
%In cases where the model will be used for inference after learning the quality of the learning process should be measured by the quality of the result of the approximate inference algorithm.
%In such cases, the quality of the learning process will be measured by the quality of the results of the approximate algorithm. 
%Therefore, inference quality needs to be assured - the learned  model must belong to a family of models where the inference is known to give good approximation.
To show theoretical guarantees in this case, we focus on a regime where BP is known to perform well, 
namely the family of High Girth Correlation Decay (HGCD) models. HGCD models are graphical models where the marginals of each variable are determined mostly by their tree shaped neighborhood, rather than  by longer cycles. 

In the paper we present an algorithm to learn the structure and parameters of such models.
The structure learning algorithm is a natural extension to \cite{chowLiu}, where we replace the tree constraint with the constraint on the girth.
Parameter learning is also similar to Chow Liu, but with a subtle clamping procedure required to keep the HGCD property\footnote{The procedure we provide is specific to the binary pairwise case. Generalization to more complex cases is non-trivial, as it requires a notion of interaction strength for the non-binary case.}.
We provide several sample complexity results. 
For structure learning, we show that if training samples are generated from an HGCD model, then under certain conditions, the model can be exactly reconstructed.
More importantly, we show that if the number of samples is large enough, then the error of the inference algorithm can be bounded, when averaged over queries.

The third paper, \secref{sec:impnet}, turns to the topic of integrating deep learning and kernels.
In it, we show that extending the class of deep learning models results in a kernel based method.
The relevant kernel can be calculated in closed form for some architectures and we provide a detailed analysis for such a case.
We provide sample complexity results, and highlight the fact that ease of optimization comes at the cost of exponentially more training samples.
Empirical results show that our method outperforms other kernel based methods, and is competitive with some non kernel based ones.  

%In the third paper \secref{sec:impnet} we present a kernel the hypothesis class of which is a combination of deep networks with a given network structure. This work follows the work of \cite{cho2009kernel}, although while their kernel relates to infinite networks, ours relates to a finite number of nodes.

\subsection{Future Work}
I will next propose directions for future work which may be of interest.

Our results for BP in \secref{sec:lwbethe} emphasize the limitations of using BP as an approximate inference algorithm. However, one natural approach to overcome this difficulty is to use BP for partition function approximation. To see this, note that an exact singleton marginal can be calculated as:
\be
\mu_i^{\thetav}(x_i) = \frac{Z(x_i;\thetav)}{\sum_{\hat{x}_i}Z(\hat{x}_i;\thetav)}
\label{eq:marg_partition}
\ee
where $Z(x_i;\thetav)$ 
% = \sum_{\hat{\xx}, \hat{\xx}_i = x_i}  
is the partition function when the $i$ variable is set to $x_i$.  

This can naturally be turned into a Bethe based approximation by replacing the log partition function with its Bethe based approximation $A_B(\thetav)$ (see eq $5$ in \secref{sec:lwbethe} or \eqref{eq:bethe_approximation} \todo{ref equation in paper}). The resulting approximation is:
\be
\tau_i^{\thetav}(x_i)= \frac{\exp{A_B(x_i;\thetav)}}{\sum_{\hat{x}_i}\exp{A_B(\hat{x}_i;\thetav)}} .~
\ee
There are several interesting theoretical and algorithmic issues with this proposal. First, it requires a different partition function estimate for each variable $X_i$ and assignment $x_i$, and this translates to many different BP runs. However, it is conceivable that these BP runs will have similar computation trees, and thus computation may be saved. A second question is how good this approximation can be in theory. For example, if $A_B(\thetav)$ corresponds to the exact minimum of the Bethe partition function\footnote{Note that we do not have the $\arg\min$ problem of marginal estimation.}, what can be said about the quality of approximation for different models. Third, what is the best way to learn parameters $\thetav$ if this is the inference method.

Our HGCD results show that in some cases, the BP computation tree should be truncated to a tree shaped neighbourhood. A generalization of this approach is to assume that each probabilistic query corresponds to a truncated computation tree. A moment matching objective for such a process may be devised, and again there are many interesting algorithmic and theoretical questions.  

\ignore{
The hardness results of learning and infernce of GM imply that maybe a more direct approach is in order.
The desired model should be able to answer different queries, for structure output.
The richness of models with correlation decay suggests, that even when only a small number of variables effect each other, rich models can still be designed.
Another related fact is that in many cases, running BP for only a small number of iterations results in good approximation to the marginals;
if so, can a model be defined, such that imitates the behavior of running BP of a small number of iterations?
One way to implement this is by a model constructing for each variable its computation tree of BP to a certain depth,
while the parameters between any two variables are tied throughout the trees.
The inference will be defined as recalculating the computation tree for any assignment (when a variable is observed, all its instances should be assigned).
}

Pseudo-Likelihood (PL) is also an interesting algorithm in the context of inferning. On the one hand, learning with PL is consistent. On the other hand, PL does not imply an inference algorithm. A fascinating question in this context is whether there exists an inference algorithm that is ``compatible'' with PL. As PL is consistent, such an algorithm in the exact sense is unlikely to be found.
But, can an efficient algorithm be found that will guarantee moment matching? An interesting
step in this direction was recently proposed in \cite{bertasius2016local}.
%Note that a moment in PL means not only the factor itself, but includes its neighbourhood as well.

PL is an instance of a larger set of methods, called composite likelihood. While PL breaks down the probability to each vertex and its neighbours, composite likelihood breaks it down to larger sets.
As long as each set is easy to calculate, the time complexity does not change much - though sample complexity depends on the larger set and its neighbours.
An interesting direction will be to optimize, during learning, how the model should be broken down - and what the best sets are \cite{dillon2010stochastic}.

Approximate inference in learning and probabilistic queries will continue to be utilized in the near future. This is also true in the age of deep learning, where generative models are highly useful, and still benefit from variational approximations \cite{kingma2013auto}.
I expect questions such as those raised here to be of relevance for these future works as well. 

%Hence, its implications need further research for both aspects -  using the approximate algorithm in the learning process, and the use of the model with a specific approximate algorithm.
%I hope that when GM will come back to fashion, these aspects will not be overlooked.

\ignore{
The research of structure learning algorithm is now at a turning point.
In the general case the time complexity lower bounds and known algorithm are very close but both impractical (exponential in the maximum degree).
So, in my opinion, the interesting direction is to defined a class that structure can be learned efficiently.
The challenge is to go beyond the pairwise case finding other criteria that will allow structure learning.

\section{Results summery}
\subsection{What cannot be learned with Bethe approximations}
A common  practice is to use BP as the approximate inference algorithm when optimizing likelihood by gradient descent .
%In the paper \cite{heinemann2012cannot} we were looking at the implication of the optimization of ML objective while the inference is BP.
As was explain before \secref{sec:Bethe_ML}, it turn out that the optimized objective is the Bethe ML \eqref{eq:bethe_like} and not ML \eqref{eq:ML}.
Bethe ML is a convex function of the optimized parameter $\thetav$, although not a smooth one, so optimization should be feasible.
Writing the equation for the optimality of the parameters \eqref{eq:bethe_opt} gave similar condition to the moment matching equations \eqref{eq:moment_matching}.
There is, however, one big different - were there are more than one pseudo-marginals that maximize the Bethe likelihood there is no guarantees that moment matching exist.

The importance of moment matching can be stressed by loss of information.
Running inference on a model learned by ML result in the empirical marginals the model was learned from. 
Hence in learning no information was lost\footnote{This is only exact with infinite data - where the learned parameters are exact. In the finite case the parameters are inexact and higher moments of the learned model may differ from the empirical ones.}.
On the other hand, where there is no moment matching the empirical marginals can not be inferred from the model.
 This reveal a loss of information by the learning process.
Hence moment matching is a crucial characteristic of learning GM.
But is there such empirical marginals - marginals that for all parameters will never be the only pseudo-marginal that minimize the Bethe free energy?
Can such marginals be characterize?

In the paper \cite{heinemann2012cannot} we give the surprising answer is of yes.
There are marginals inside the marginal polytope(\eqref{eq:margpoly}) that for all parameters they are not the sole minimizer of the Bethe free energy.
This imply, that if the empirical marginals are such, the parameters that maximize the Bethe likelihood can not reconstruct the empirical marginals - no moment matching.
Note, that in this case optimizing by gradient descent will have difficulty to converge since BP may return marginals that are far a way from each other in each iteration.
This encourage the definition of a new set of marginals - Bethe learn-able.
A marginal is Bethe learn-able if there exist a parameter that this marginal is the only pseudo-marginal that minimize the Bethe free energy for this parameter.
I our paper bounds to this set is given.

Lets start from inner bounds.
As mentioned above, convergence of BP is a topic of active research moreover the found conditions not only guarantee convergence but convergence to a sole marginals.
This is very close to what is needed for inner bound, but the conditions are the other way around - they constrains the \textit{parameters} such a sole minimizer is guaranteed.
We close this gap using the canonical parameters \eqref{eq:canonical} which can be thought as a map between empirical marginals to parameters.
Using the fact that the marginals are always a fix point of BP, not necessarily stable, for their canonical marginals.
The inner bound is define as all the marginals that their canonical parameters satisfy one of the convergence conditions.

Discovery of the outer bounds is more of a challenge since their very existence being proof to the existence of the unbelievable marginals \cite{pitkow2011learning}\footnote{This paper was published after to publication of our paper.}.
The canonical parameters can be used to define such bounds as well.
Any marginals that running BP on its canonical parameters do not always return the same marginals are not Bethe learn-able.
This indeed define an outer bound but is such marginals exists? can an explicit bound be found.
In the paper we define a closed form bounds using the Hessian of the Bethe likelihood.
Close look at the Hessian will reveal that it is a function of the marginals a lone.
Hence if the Hessian of the marginals is not negative semi-definite these marginals are not Bethe learn-able.
This, though a clear function of the marginals, is not closed form equation.
For this end, we restrict our model to be binary and homogeneous. 
A closed form equation is given that give a condition for the pairwise marginals given the singleton marginals and the number of edges in the graph.
Note that this is the first proof (to my knowledge) that there are marginals that will never be a stable point of BP - which mean, in some way, that BP is biased.

To conclude, we defined a set of marginals that could be learned with Bethe ML and achieve moment matching.
We gave inner and outer bounds for this set and prove that there are marginals outside this set.
Note that for marginals in this set the canonical marginals are optimal.  

\subsection{Inferning with high girth graphical models}
Learning models when our goal is to use the model for inference is different than trying to reconstruct the exact model.
The quality of the learning process is asses by the quality of the inference and not by how close the model is to the real one.
To this end, the inference quality needed to be assured  - the learned  model must belong to a family of models where the inference is known to give good approximation.
Trees is such a family - and indeed \cite{chowLiu} give present an algorithm learned the tree models where the parameters are the canonical parameters \eqref{eq:canonical}
But tree are very limited family of models, a broader family is the locally tree or High Girth Correlation Decay (HGCD) models where inference by BP is guaranteed to give good approximation.
HGCD models are models that for every vertex its surrounding is a tree, where a vertex belongs to other surrounding if a change in its assignment effect it marginals in non-negligible way.
In \cite{heinemann2014inferning} we present an algorithm that guarantee to return a model in HGCD.

In the paper we present an algorithm to learn the structure of the model.
The algorithm is a natural extension to \cite{chowLiu} where we replace the tree constrain with the constrain of the girth\footnote{The girth of a graph is the length of its shortest cycle. The girth of a tree is infinite.}.
Parameters are the canonical parameters but to insure correlation decay the input marginals strength may be needed to clamp down\footnote{We know how to do it only in the binary pairwise case. In the general case I am not aware on a good way to measure the interaction strength between the variables.}.
We prove that if the sample are generated from a model from this family.
Under some conditions, the models can be reconstruct.
More importantly, we showed that if the number of samples are big enough the error of the inference algorithm can be bounded.
}
