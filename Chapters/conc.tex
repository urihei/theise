% !TEX root =../main.tex
\chapter{Conclusion and Discussion } % Main chapter title
\label{con} % For referencing the chapter elsewhere, use \ref{con} 
The name ``learning using an approximate inference''  attempts to cover two aspects of the learning process.
First, in the process of learning one uses an approximation inference.
Second, after learning, the model will be used with an approximate inference, and the quality of learning will be measured by the quality of the inference.

The first paper \secref{sec:lwbethe} clarifies the implication of using BP as the approximate inference in the learning process.
It appears that the optimized objective is the Bethe ML \eqref{eq:bethe_like} and not ML \eqref{eq:ML}.
We show that although Bethe ML is a convex function, as it is not smooth- learning must be done with care.
More specifically, we define a set of marginals that could safely be learned by Bethe ML.
Furthermore, for empirical marginals in this set, we show that the canonical parameters \eqref{eq:canonical} maximize the Bethe ML, and no gradient descent is needed;
while for marginals outside this set, there are no parameters guaranteeing moment-matching \eqref{eq:moment_matching}, translating into parameters of questionable use.
We give an inner and outer bound for this set.
The existence of outer bounds to this set, which cross the marginal polytope, prove the existence of marginals that will never be a sole fix point of BP, or even a stable fix point at all.

The second paper addresses the second aspect, how to learn when knowing that the model will be used for inference by a known approximate inference.
%Remembering the fact that the quality of the learning process is asses by the quality of the results of the approximate inference and not by how close the model is to the real one.
%In cases where the model will be used for inference after learning the quality of the learning process should be measured by the quality of the result of the approximate inference algorithm.
In such cases, the quality of the learning process will be measured by the quality of the results of the approximate algorithm. 
Therefore, inference quality needs to be assured - the learned  model must belong to a family of models where the inference is known to give good approximation.
In \secref{sec:lg} we present an algorithm that guarantees returning a model that belongs to the family of High Girth Correlation Decay (HGCD), a model family on which BP is guaranteed to return good approximations .
HGCD models are models in which the surrounding for every vertex is a tree, where a vertex belongs to other vertex's surrounding if a change in its assignment effects the other vertex marginals in a non-negligible way.

In the paper we present an algorithm to learn the structure and parameters of the model.
The structure learning algorithm is a natural extension to \cite{chowLiu}, where we replace the tree constraint with the constraint on the girth\footnote{The girth of a graph is the length of its shortest cycle. The girth of a tree is infinite.}.
Parameters are the canonical parameters, but to insure correlation decay, it may be necessary for the empirical marginals' interaction strength to be clamped down\footnote{We know how to do this only in the binary pairwise case. In the general case, I am not aware of an adequate way to measure the interaction strength between the variables.}.
We prove that if the samples are generated from a model from this family, then under certain conditions, the models can be reconstructed.
More importantly, we show that if the number of samples is large enough, then the error of the inference algorithm can be bounded.

In the third paper \secref{sec:impnet} we present a kernel the hypothesis class of which is a combination of deep networks with a given network structure. This work follows the work of \cite{cho2009kernel}, although while their kernel relates to infinite networks, ours relates to a finite number of nodes.

\subsection{Future Work}
I will now suggest directions for future work which may be of interest.

\claimref{thm:bp_bethe} gives meaning to the fix point of BP - they are the pseudo-marginals that minimize the Bethe free energy.  
The variational point of view shows, that the argument that minimizes the free energy is indeed the marginal of the model.
From here it is concluded that the pseudo-marginals that minimize the Bethe free energy are approximations to the true marginal.
This conclusion is problematic in case of multiple minima - the resulted marginals sould not be thought of as an approximation of the true marginals (and empirically they usually are of very poor quality).
So how can the marginals be estimated in these cases?
A simple way to calculate a single marginal is to note that $\mu_i^{\thetav}(x_i) = \frac{Z(x_i;\thetav)}{\sum_{\hat{x}_i}Z(\hat{x}_i;\thetav)}$, where $Z(x_i;\thetav)$% = \sum_{\hat{\xx}, \hat{\xx}_i = x_i}  
is the partition function when the $i$ variable is set to $x_i$.
The approximation will now be $\tau_i^{\thetav} = \frac{\exp{A_B(x_i;\thetav)}}{\sum_{\hat{x}_i}\exp{A_B(\hat{x}_i;\thetav)}}$.
The problem with this approximation is that for each variable assignment, one should run BP; 
however, may the previous runs be used to accelerate BP convergence, so BP will run for only a few iterations?
Could this method be efficient enough for use?

The hardness results of learning and infernce of GM imply that maybe a more direct approach is in order.
The desired model should be able to answer different queries, for structure output.
The richness of models with correlation decay suggests, that even when only a small number of variables effect each other, rich models can still be designed.
Another related fact is that in many cases, running BP for only a small number of iterations results in good approximation to the marginals;
if so, can a model be defined, such that imitates the behavior of running BP of a small number of iterations?
One way to implement this is by a model constructing for each variable its computation tree of BP to a certain depth,
while the parameters between any two variables are tied throughout the trees.
The inference will be defined as recalculating the computation tree for any assignment (when a variable is observed, all its instances should be assigned).


Pseudo-Likelihood (PL) has many appealing features.
Learning is feasible, and although it is less sample efficient than ML, it is still consistent.
This work argues, that the inference algorithm to be used on the learned model should be taken into account when learning.
Can an algorithm be found that insures PL inference quality?
As PL is consistent, such an algorithm is unlikely to be found.
So, can an efficient algorithm be found that will guarantee moment matching?
Note that a moment in PL means not only the factor itself, but includes its neighbourhood as well.

PL is an example of a larger set of methods, called composite likelihood.
While PL breaks down the probability to each vertex and its neighbours, composite likelihood breaks it down to larger sets.
As long as each set is easy to calculate, the time complexity does not change much - though sample complexity depends on the larger set and its neighbours.
An interesting direction will be to optimize, during learning, how the model should be broken down - what the best sets are.

Approximate infernce in learning will continue to be utilized in the near future.
Hence, its implications need further research for both aspects -  using the approximate algorithm in the learning process, and the use of the model with a specific approximate algorithm.
I hope that when GM will come back to fashion, these aspects will not be overlooked.

\ignore{
The research of structure learning algorithm is now at a turning point.
In the general case the time complexity lower bounds and known algorithm are very close but both impractical (exponential in the maximum degree).
So, in my opinion, the interesting direction is to defined a class that structure can be learned efficiently.
The challenge is to go beyond the pairwise case finding other criteria that will allow structure learning.

\section{Results summery}
\subsection{What cannot be learned with Bethe approximations}
A common  practice is to use BP as the approximate inference algorithm when optimizing likelihood by gradient descent .
%In the paper \cite{heinemann2012cannot} we were looking at the implication of the optimization of ML objective while the inference is BP.
As was explain before \secref{sec:Bethe_ML}, it turn out that the optimized objective is the Bethe ML \eqref{eq:bethe_like} and not ML \eqref{eq:ML}.
Bethe ML is a convex function of the optimized parameter $\thetav$, although not a smooth one, so optimization should be feasible.
Writing the equation for the optimality of the parameters \eqref{eq:bethe_opt} gave similar condition to the moment matching equations \eqref{eq:moment_matching}.
There is, however, one big different - were there are more than one pseudo-marginals that maximize the Bethe likelihood there is no guarantees that moment matching exist.

The importance of moment matching can be stressed by loss of information.
Running inference on a model learned by ML result in the empirical marginals the model was learned from. 
Hence in learning no information was lost\footnote{This is only exact with infinite data - where the learned parameters are exact. In the finite case the parameters are inexact and higher moments of the learned model may differ from the empirical ones.}.
On the other hand, where there is no moment matching the empirical marginals can not be inferred from the model.
 This reveal a loss of information by the learning process.
Hence moment matching is a crucial characteristic of learning GM.
But is there such empirical marginals - marginals that for all parameters will never be the only pseudo-marginal that minimize the Bethe free energy?
Can such marginals be characterize?

In the paper \cite{heinemann2012cannot} we give the surprising answer is of yes.
There are marginals inside the marginal polytope(\eqref{eq:margpoly}) that for all parameters they are not the sole minimizer of the Bethe free energy.
This imply, that if the empirical marginals are such, the parameters that maximize the Bethe likelihood can not reconstruct the empirical marginals - no moment matching.
Note, that in this case optimizing by gradient descent will have difficulty to converge since BP may return marginals that are far a way from each other in each iteration.
This encourage the definition of a new set of marginals - Bethe learn-able.
A marginal is Bethe learn-able if there exist a parameter that this marginal is the only pseudo-marginal that minimize the Bethe free energy for this parameter.
I our paper bounds to this set is given.

Lets start from inner bounds.
As mentioned above, convergence of BP is a topic of active research moreover the found conditions not only guarantee convergence but convergence to a sole marginals.
This is very close to what is needed for inner bound, but the conditions are the other way around - they constrains the \textit{parameters} such a sole minimizer is guaranteed.
We close this gap using the canonical parameters \eqref{eq:canonical} which can be thought as a map between empirical marginals to parameters.
Using the fact that the marginals are always a fix point of BP, not necessarily stable, for their canonical marginals.
The inner bound is define as all the marginals that their canonical parameters satisfy one of the convergence conditions.

Discovery of the outer bounds is more of a challenge since their very existence being proof to the existence of the unbelievable marginals \cite{pitkow2011learning}\footnote{This paper was published after to publication of our paper.}.
The canonical parameters can be used to define such bounds as well.
Any marginals that running BP on its canonical parameters do not always return the same marginals are not Bethe learn-able.
This indeed define an outer bound but is such marginals exists? can an explicit bound be found.
In the paper we define a closed form bounds using the Hessian of the Bethe likelihood.
Close look at the Hessian will reveal that it is a function of the marginals a lone.
Hence if the Hessian of the marginals is not negative semi-definite these marginals are not Bethe learn-able.
This, though a clear function of the marginals, is not closed form equation.
For this end, we restrict our model to be binary and homogeneous. 
A closed form equation is given that give a condition for the pairwise marginals given the singleton marginals and the number of edges in the graph.
Note that this is the first proof (to my knowledge) that there are marginals that will never be a stable point of BP - which mean, in some way, that BP is biased.

To conclude, we defined a set of marginals that could be learned with Bethe ML and achieve moment matching.
We gave inner and outer bounds for this set and prove that there are marginals outside this set.
Note that for marginals in this set the canonical marginals are optimal.  

\subsection{Inferning with high girth graphical models}
Learning models when our goal is to use the model for inference is different than trying to reconstruct the exact model.
The quality of the learning process is asses by the quality of the inference and not by how close the model is to the real one.
To this end, the inference quality needed to be assured  - the learned  model must belong to a family of models where the inference is known to give good approximation.
Trees is such a family - and indeed \cite{chowLiu} give present an algorithm learned the tree models where the parameters are the canonical parameters \eqref{eq:canonical}
But tree are very limited family of models, a broader family is the locally tree or High Girth Correlation Decay (HGCD) models where inference by BP is guaranteed to give good approximation.
HGCD models are models that for every vertex its surrounding is a tree, where a vertex belongs to other surrounding if a change in its assignment effect it marginals in non-negligible way.
In \cite{heinemann2014inferning} we present an algorithm that guarantee to return a model in HGCD.

In the paper we present an algorithm to learn the structure of the model.
The algorithm is a natural extension to \cite{chowLiu} where we replace the tree constrain with the constrain of the girth\footnote{The girth of a graph is the length of its shortest cycle. The girth of a tree is infinite.}.
Parameters are the canonical parameters but to insure correlation decay the input marginals strength may be needed to clamp down\footnote{We know how to do it only in the binary pairwise case. In the general case I am not aware on a good way to measure the interaction strength between the variables.}.
We prove that if the sample are generated from a model from this family.
Under some conditions, the models can be reconstruct.
More importantly, we showed that if the number of samples are big enough the error of the inference algorithm can be bounded.
}
